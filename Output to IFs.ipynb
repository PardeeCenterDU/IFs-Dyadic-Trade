{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFs\n",
    "- Actors are exporters\n",
    "- DataDict has inconsistent series names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('D:/IFsDyadSeries/DyadicHistSeriesAndDataDict 20250204/DataDictDyadic.db')\n",
    "cursor = conn.cursor()\n",
    "dd = pd.read_sql_query(\"SELECT * from DataDict\", conn)\n",
    "conn.close()\n",
    "Sectors=[\"Agri\",\"Manu\",\"Mate\",\"ICT\",\"Ener\", \"Goods\"]\n",
    "tb_list = []\n",
    "for s in Sectors:\n",
    "    for tb in dd.Table:\n",
    "        if tb.endswith(s) or tb.endswith(s[:3]) or tb.endswith(s[:2]):\n",
    "            tb_list.append(tb)\n",
    "tb_list.sort()\n",
    "assert len(tb_list) == 5*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifs_country = pd.read_excel(\"concordance/ccode_Comtrade_BACI_WITS_20241113.xlsx\")\n",
    "ifs_country = ifs_country[[\"Country\",\"FIPS_CODE\"]].drop_duplicates().dropna()\n",
    "ifs_fips = dict(zip(ifs_country.Country, ifs_country.FIPS_CODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(list(combinations(ifs_country.Country.unique(), 2)))\n",
    "df_1.columns = [\"Actor\", \"Partner\"]\n",
    "df_2 = pd.DataFrame(list(combinations(ifs_country.Country.unique(), 2)))\n",
    "df_2.columns = [\"Partner\", \"Actor\"]\n",
    "df = pd.concat([df_1,df_2], sort=False)\n",
    "del df_1, df_2\n",
    "df[\"Actor_FIPS\"] = df[\"Actor\"].map(ifs_fips)\n",
    "df[\"Partner_FIPS\"] = df[\"Partner\"].map(ifs_fips)\n",
    "df = df[[\"Actor\", \"Actor_FIPS\", \"Partner\", \"Partner_FIPS\"]]\n",
    "assert df.shape[0] == 188*187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_start = 1995\n",
    "y_end = 2022\n",
    "tci_list = []\n",
    "for f in os.listdir(\"output/tci_ifscountry\"):\n",
    "    for y in range(y_start, y_end+1):\n",
    "        if str(y) in f:\n",
    "            dt = pd.read_csv(f\"output/tci_ifscountry/{f}\", encoding=\"latin-1\")\n",
    "            dt[\"Year\"] = y\n",
    "            tci_list.append(dt)\n",
    "tci = pd.concat(tci_list)\n",
    "del tci_list, dt\n",
    "tci_s = tci[[\"Year\",'Exporter', 'Importer', 'IFsSector', 'TCIExAImBPctS']].copy()\n",
    "tci_s.rename(columns={\"TCIExAImBPctS\":\"TCI\"}, inplace=True)\n",
    "tci_w = tci[[\"Year\",'Exporter', 'Importer', 'TCIExAImBPctW']].drop_duplicates().copy()\n",
    "tci_w[\"IFsSector\"] = \"Goods\"\n",
    "tci_w.rename(columns={\"TCIExAImBPctW\":\"TCI\"}, inplace=True)\n",
    "tci = pd.concat([tci_s, tci_w] , sort=False)\n",
    "tci.rename(columns={\"Exporter\":\"Actor\", \"Importer\":\"Partner\"}, inplace=True)\n",
    "del tci_s,tci_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tb in tb_list:\n",
    "    if \"TCI\" not in tb:\n",
    "        continue\n",
    "    sec = tb.replace(\"SeriesTCI\", \"\")\n",
    "    tci_s = tci[tci.IFsSector==sec].pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"TCI\").reset_index()\n",
    "    dt = pd.merge(left=df, right=tci_s, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "    # takes about 1-2mins for all tables\n",
    "    Ear=[]\n",
    "    Rec=[]\n",
    "    for i in range(dt.shape[0]):\n",
    "        line=dt.iloc[i,4:]\n",
    "        line.dropna(inplace=True)\n",
    "        if not line.empty:\n",
    "            Ear.append(line.values[0])\n",
    "            Rec.append(line.values[-1])\n",
    "        else:\n",
    "            Ear.append(np.NaN)\n",
    "            Rec.append(np.NaN)\n",
    "    dt[\"Earliest\"]=Ear\n",
    "    dt[\"MostRecent\"]=Rec\n",
    "    dt.to_csv(f\"output/IFs Format/{tb}.csv\", index=False, encoding=\"latin-1\")\n",
    "del tci, tci_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rev, WtTariff, Trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trw_list = []\n",
    "for y in range(y_start, y_end+1):\n",
    "    dt = pd.read_csv(f\"output/trade_wt_rev_2017usd_ifscountry/{y}.csv\", encoding=\"latin-1\")\n",
    "    dt[\"Year\"] = y\n",
    "    trw_list.append(dt)\n",
    "trw = pd.concat(trw_list)\n",
    "del trw_list, dt\n",
    "trw.IFsSector = trw.IFsSector.replace({\"AllGoods\":\"Goods\"})\n",
    "trw.rename(columns={\"Exporter\":\"Actor\", \"Importer\":\"Partner\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rev\n",
    "for tb in tb_list:\n",
    "    if \"TariffRev\" not in tb:\n",
    "        continue\n",
    "    sec = tb.replace(\"SeriesTariffRev\", \"\")\n",
    "    rev_s = trw[trw.IFsSector==sec].pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"Rev\").reset_index()\n",
    "    dt = pd.merge(left=df, right=rev_s, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "    # takes about 1-2mins for all tables\n",
    "    Ear=[]\n",
    "    Rec=[]\n",
    "    for i in range(dt.shape[0]):\n",
    "        line=dt.iloc[i,4:]\n",
    "        line.dropna(inplace=True)\n",
    "        if not line.empty:\n",
    "            Ear.append(line.values[0])\n",
    "            Rec.append(line.values[-1])\n",
    "        else:\n",
    "            Ear.append(np.NaN)\n",
    "            Rec.append(np.NaN)\n",
    "    dt[\"Earliest\"]=Ear\n",
    "    dt[\"MostRecent\"]=Rec\n",
    "    dt.to_csv(f\"output/IFs Format/{tb}.csv\", index=False, encoding=\"latin-1\")\n",
    "del rev_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WtTariff\n",
    "for tb in tb_list:\n",
    "    if \"WtTariff\" not in tb:\n",
    "        continue\n",
    "    sec = tb.replace(\"SeriesWtTariff\", \"\")\n",
    "    wt_s = trw[trw.IFsSector==sec].pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"WtTariff\").reset_index()\n",
    "    dt = pd.merge(left=df, right=wt_s, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "    # takes about 1-2mins for all tables\n",
    "    Ear=[]\n",
    "    Rec=[]\n",
    "    for i in range(dt.shape[0]):\n",
    "        line=dt.iloc[i,4:]\n",
    "        line.dropna(inplace=True)\n",
    "        if not line.empty:\n",
    "            Ear.append(line.values[0])\n",
    "            Rec.append(line.values[-1])\n",
    "        else:\n",
    "            Ear.append(np.NaN)\n",
    "            Rec.append(np.NaN)\n",
    "    dt[\"Earliest\"]=Ear\n",
    "    dt[\"MostRecent\"]=Rec\n",
    "    dt.to_csv(f\"output/IFs Format/{tb}.csv\", index=False, encoding=\"latin-1\")\n",
    "del wt_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trade\n",
    "sec_dict = {\"En\" : \"Ener\", \"Ag\":\"Agri\", \"Man\": \"Manu\", \"Mat\":\"Mate\", \"ICT\": \"ICT\", \"Goods\":\"Goods\"}\n",
    "for tb in tb_list:\n",
    "    # In Export tables, actors are exporters\n",
    "    if \"Exports\" in tb:\n",
    "        sec = tb.replace(\"SeriesExports\", \"\")\n",
    "        sec = sec_dict[sec]\n",
    "        trade_s = trw[trw.IFsSector==sec].pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"Trade\").reset_index()\n",
    "        dt = pd.merge(left=df, right=trade_s, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "    # In Import tables, actors are importers\n",
    "    elif \"Imports\" in tb:\n",
    "        sec = tb.replace(\"SeriesImports\", \"\")\n",
    "        sec = sec_dict[sec]\n",
    "        trade_s = trw[trw.IFsSector==sec].pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"Trade\").reset_index()\n",
    "        trade_s.rename(columns={\"Actor\":\"Partner\", \"Partner\":\"Actor\"}, inplace=True)\n",
    "        dt = pd.merge(left=df, right=trade_s, on=[\"Actor\",\"Partner\"], how=\"left\") \n",
    "    else:\n",
    "        continue\n",
    "    # takes about 1-2mins for all tables\n",
    "    Ear=[]\n",
    "    Rec=[]\n",
    "    for i in range(dt.shape[0]):\n",
    "        line=dt.iloc[i,4:]\n",
    "        line.dropna(inplace=True)\n",
    "        if not line.empty:\n",
    "            Ear.append(line.values[0])\n",
    "            Rec.append(line.values[-1])\n",
    "        else:\n",
    "            Ear.append(np.NaN)\n",
    "            Rec.append(np.NaN)\n",
    "    dt[\"Earliest\"]=Ear\n",
    "    dt[\"MostRecent\"]=Rec\n",
    "    dt.to_csv(f\"output/IFs Format/{tb}.csv\", index=False, encoding=\"latin-1\")\n",
    "del trade_s, trw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To DB file\n",
    "- Run this whenever you have all the IFs formatted files ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_list_all = [*tb_list, *[\"SeriesExportsTotal\", 'SeriesImportsTotal', \"SeriesExportsServ\", 'SeriesImportsServ']]\n",
    "# took less than 2mins\n",
    "conn = sqlite3.connect('D:/IFsDyadSeries/DyadicHistSeriesAndDataDict 20250204/IFsHistSeriesDyadic.db')\n",
    "cursor = conn.cursor()\n",
    "#\n",
    "for tb in tb_list_all:\n",
    "    dt = pd.read_csv(f\"output/IFs Format/{tb}.csv\", encoding=\"latin-1\")\n",
    "    sql_drop_table = f\"DROP TABLE IF EXISTS [{tb}];\"\n",
    "    sql_create_table = f\"CREATE TABLE [{tb}] (Actor VARCHAR (255), Actor_FIPS VARCHAR (255), Partner VARCHAR (255), Partner_FIPS VARCHAR (255), \"\n",
    "    for c in dt.columns[4:]:\n",
    "        sql_create_table += f\"[{c}] DOUBLE(53),\"\n",
    "    sql_create_table = sql_create_table[:-1] + \");\"\n",
    "    cursor.execute(sql_drop_table)\n",
    "    cursor.execute(sql_create_table)\n",
    "    dt.to_sql(name=f'{tb}', con=conn, if_exists=\"append\", index=False)\n",
    "    conn.commit()\n",
    "conn.close()\n",
    "#\n",
    "dd = pd.read_excel(\"DataDict Trade Dyadic 20250204.xlsx\")\n",
    "conn = sqlite3.connect('D:/IFsDyadSeries/DyadicHistSeriesAndDataDict 20250204/DataDictDyadic.db')\n",
    "cursor = conn.cursor()\n",
    "for tb in tb_list_all:\n",
    "    sql_del_row_dd = 'DELETE FROM DataDict WHERE \"Table\" = ?;'\n",
    "    cursor.execute(sql_del_row_dd, (tb,))\n",
    "dd.to_sql(name=f'DataDict', con=conn, if_exists=\"append\", index=False)  \n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
