{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sqlite3\n",
    "import time\n",
    "from itertools import combinations\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing\n",
    "__Columns needed__ </br>\n",
    "'refYear', 'flowCode'</br>\n",
    "'reporterCode', 'reporterDesc', 'partnerCode', 'partnerDesc' </br>\n",
    "'classificationSearchCode', 'cmdCode', 'cmdDesc', 'aggrLevel', 'isLeaf' </br>\n",
    "'cifvalue', 'fobvalue', 'primaryValue' </br>\n",
    "\n",
    "__Notes__ </br>\n",
    "\"CIF value\" refers to the \"Cost, Insurance, and Freight\" price of a good, which includes the cost of the product itself, the cost of shipping it to the destination port, and the insurance cost for the journey, while \"primary value\" generally refers to the inherent worth of a product based on its intrinsic qualities and intended use, without considering additional costs like shipping or insurance; essentially, the base price of the good itself. It seems in total service trade, cifvalue = primaryValue. </br>\n",
    "For both goods & service, we use reported exports as the baseline, because that's normally the \"FOB\" value; Although \"CIF\" in imports generate tariff revenue</br>\n",
    "Values are in current USD, need to be constant $2011 or $2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the country concordacne table\n",
    "c_map = pd.read_excel(\"concordance/ccode_Comtrade_BACI_WITS_20241113.xlsx\")\n",
    "c_ifs = c_map.Country.unique()[:188]\n",
    "# following steps only need to be ran to check for changes in country names from the raw data\n",
    "# c_uncomtrade = list(set(c_reporter.reporterDesc.str.strip()) | set(c_partner.PartnerDesc.str.strip()))\n",
    "# c_uncomtrade.sort()\n",
    "# for c in c_uncomtrade:\n",
    "#     if c not in c_ifs:\n",
    "#         print(c.__repr__())\n",
    "# for c in c_ifs:\n",
    "#     if c not in c_uncomtrade:\n",
    "#         print(c.__repr__())\n",
    "# create a dictionary that matches UN Comtrade entity names with IFs entity names\n",
    "c_comtrade_ifs_serv = c_map[['UNComtrade_Service', 'Country']].dropna()\n",
    "dict_comtrade_ifs_serv = dict(zip(c_comtrade_ifs_serv.UNComtrade_Service, c_comtrade_ifs_serv.Country))\n",
    "# total serv trade\n",
    "df_list = []\n",
    "for year in range(2000,2024):   \n",
    "    df = pd.read_csv(f\"data/UNComtrade_TotalService_20241112/Service_EBOPS_{year}.csv\", low_memory=False, \n",
    "                     usecols=['refYear', 'reporterCode', 'reporterDesc', 'partnerCode', 'partnerDesc', 'flowCode', \n",
    "                              'classificationSearchCode', 'cmdCode', 'cmdDesc', 'aggrLevel', 'isLeaf',\n",
    "                              'cifvalue', 'fobvalue', 'primaryValue'])\n",
    "    df.reporterDesc = df.reporterDesc.str.strip()\n",
    "    df.partnerDesc = df.partnerDesc.str.strip()\n",
    "    df = df[(df.reporterDesc.isin(dict_comtrade_ifs_serv)) & (df.partnerDesc.isin(dict_comtrade_ifs_serv))]\n",
    "    # df[(df.reporterDesc.isin(dict_comtrade_ifs_serv))&(df.partnerDesc.isin(dict_comtrade_ifs_serv))&(df.cmdDesc.str.contains(\"otal\"))]\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)\n",
    "del df_list\n",
    "# the next line is checking the differences between CIF value and primary value\n",
    "# (df.cifvalue/df.primaryValue).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to IFs country name\n",
    "df[\"reporter\"] = df.reporterDesc.replace(dict_comtrade_ifs_serv)\n",
    "df[\"partner\"] = df.partnerDesc.replace(dict_comtrade_ifs_serv) \n",
    "# the purpose of the rest of this section is to fill in trade values that are only reported by one side\n",
    "df_m = df[df.flowCode==\"M\"][[\"refYear\", \"reporter\", \"partner\", \"cmdCode\", \"primaryValue\"]].copy()\n",
    "df_x = df[df.flowCode==\"X\"][[\"refYear\", \"reporter\", \"partner\", \"cmdCode\", \"primaryValue\"]].copy()\n",
    "# No code duplicates between cmdCodes 200 & S \n",
    "# No country duplicates except for 2006 Belarus to Serbia\n",
    "# df_m[df_m.duplicated(subset=[\"refYear\", \"reporter\", \"partner\"])]\n",
    "# df_x[df_x.duplicated(subset=[\"refYear\", \"reporter\", \"partner\"])]\n",
    "df_m = df_m.groupby([\"refYear\", \"reporter\", \"partner\", \"cmdCode\"])[\"primaryValue\"].sum(min_count=1).reset_index()\n",
    "df_x = df_x.groupby([\"refYear\", \"reporter\", \"partner\", \"cmdCode\"])[\"primaryValue\"].sum(min_count=1).reset_index()\n",
    "###\n",
    "df_m = df_m[[\"refYear\", \"reporter\", \"partner\", \"primaryValue\"]]\n",
    "df_m.columns = [\"Year\", \"Actor\", \"Partner\", \"Imports\"]\n",
    "df_x = df_x[[\"refYear\", \"reporter\", \"partner\", \"primaryValue\"]]\n",
    "df_x.columns = [\"Year\", \"Actor\", \"Partner\", \"Exports\"]\n",
    "# Use exports as the baseline\n",
    "# if A is the reporter in A's exports to B, then it becomes B's imports from A (x_mirror), which overwrites B's imports from A (when B is the reporting importer)\n",
    "# if A is the reporter in A's imports from B, then it becomes B's exports to A (m_mirror), which can fill in the Nulls in B's exports to A (when B is the reporting exporter)\n",
    "df_x_mirror = df_x.copy()\n",
    "df_x_mirror.columns = [\"Year\", \"Partner\", \"Actor\", \"Imports_mirror\"]\n",
    "df_m_mirror = df_m.copy()\n",
    "df_m_mirror.columns = [\"Year\", \"Partner\", \"Actor\", \"Exports_mirror\"]\n",
    "df_x = pd.merge(left=df_x, right=df_m_mirror, on= [\"Year\", \"Actor\", \"Partner\"], how = \"outer\")\n",
    "df_m = pd.merge(left=df_m, right=df_x_mirror, on= [\"Year\", \"Actor\", \"Partner\"], how = \"outer\")\n",
    "df_x.Exports = df_x.Exports.fillna(df_x.Exports_mirror)\n",
    "df_m.Imports_mirror = df_m.Imports_mirror.fillna(df_m.Imports)\n",
    "df_mx = pd.merge(left=df_x, right=df_m, on=[\"Year\", \"Actor\", \"Partner\" ], how=\"outer\")\n",
    "df_mx = df_mx[[\"Year\", \"Actor\", \"Partner\", \"Exports\", \"Imports_mirror\"]].rename(columns={\"Imports_mirror\": \"Imports\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Actor</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Exports</th>\n",
       "      <th>Imports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Belarus</td>\n",
       "      <td>1.375095e+03</td>\n",
       "      <td>2.062643e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.838578e+06</td>\n",
       "      <td>8.956681e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>5.357375e+06</td>\n",
       "      <td>2.176474e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>7.037393e+04</td>\n",
       "      <td>2.670371e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>1.279526e+05</td>\n",
       "      <td>1.919289e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78475</th>\n",
       "      <td>2023</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.594855e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78476</th>\n",
       "      <td>2023</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>1.208749e+10</td>\n",
       "      <td>1.128693e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78477</th>\n",
       "      <td>2023</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2.490808e+10</td>\n",
       "      <td>1.709001e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78478</th>\n",
       "      <td>2023</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>3.239702e+09</td>\n",
       "      <td>4.783615e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78479</th>\n",
       "      <td>2023</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.433676e+09</td>\n",
       "      <td>2.099399e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78480 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year                     Actor         Partner       Exports  \\\n",
       "0      2000               Afghanistan         Belarus  1.375095e+03   \n",
       "1      2000                   Albania         Austria  3.838578e+06   \n",
       "2      2000                   Albania         Croatia  5.357375e+06   \n",
       "3      2000                   Albania  Czech Republic  7.037393e+04   \n",
       "4      2000                   Albania         Hungary  1.279526e+05   \n",
       "...     ...                       ...             ...           ...   \n",
       "78475  2023  United States of America           Spain           NaN   \n",
       "78476  2023  United States of America          Sweden  1.208749e+10   \n",
       "78477  2023  United States of America     Switzerland  2.490808e+10   \n",
       "78478  2023  United States of America        Thailand  3.239702e+09   \n",
       "78479  2023                  Viet Nam       Australia  1.433676e+09   \n",
       "\n",
       "            Imports  \n",
       "0      2.062643e+04  \n",
       "1      8.956681e+06  \n",
       "2      2.176474e+06  \n",
       "3      2.670371e+06  \n",
       "4      1.919289e+04  \n",
       "...             ...  \n",
       "78475  4.594855e+09  \n",
       "78476  1.128693e+10  \n",
       "78477  1.709001e+10  \n",
       "78478  4.783615e+09  \n",
       "78479  2.099399e+09  \n",
       "\n",
       "[78480 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this section converts trade values from current USD to constant $2017\n",
    "deflator=pd.read_csv(\"concordance/WDI GDP Deflator 20241119.csv\", skiprows=3)\n",
    "deflator=deflator[deflator[\"Country Name\"]==\"United States\"][[*[\"Country Name\"], *[str(y) for y in range(1995,2024)]]].copy(True)\n",
    "deflator_long = deflator.melt(id_vars=\"Country Name\", var_name=\"Year\", value_name=\"Deflator\")\n",
    "deflator_long.Year = deflator_long.Year.astype(int)\n",
    "deflator_long[\"DRatio\"] = deflator_long.loc[deflator_long.Year==2017,\"Deflator\"].values[0]/deflator_long.Deflator\n",
    "df_mx = pd.merge(left=df_mx, right=deflator_long, on=\"Year\",how=\"left\")\n",
    "df_mx[\"Exports_deflate\"] = df_mx[\"Exports\"] * df_mx[\"DRatio\"]\n",
    "df_mx[\"Imports_deflate\"] = df_mx[\"Imports\"] * df_mx[\"DRatio\"]\n",
    "df_mx = df_mx[[\"Year\", \"Actor\", \"Partner\", \"Exports_deflate\", \"Imports_deflate\"]]\n",
    "df_mx.columns = [\"Year\", \"Actor\", \"Partner\", \"Exports\", \"Imports\"]\n",
    "df_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IFs Format\n",
    "Convert the data into IFs formatting, including adding the most recent/earliest columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifs_country = pd.read_excel(\"concordance/ccode_Comtrade_BACI_WITS_20241113.xlsx\")\n",
    "ifs_country = ifs_country[[\"Country\",\"FIPS_CODE\"]].drop_duplicates().dropna()\n",
    "ifs_fips = dict(zip(ifs_country.Country, ifs_country.FIPS_CODE))\n",
    "df_1 = pd.DataFrame(list(combinations(ifs_country.Country.unique(), 2)))\n",
    "df_1.columns = [\"Actor\", \"Partner\"]\n",
    "df_2 = pd.DataFrame(list(combinations(ifs_country.Country.unique(), 2)))\n",
    "df_2.columns = [\"Partner\", \"Actor\"]\n",
    "df = pd.concat([df_1,df_2], sort=False)\n",
    "del df_1, df_2\n",
    "df[\"Actor_FIPS\"] = df[\"Actor\"].map(ifs_fips)\n",
    "df[\"Partner_FIPS\"] = df[\"Partner\"].map(ifs_fips)\n",
    "df = df[[\"Actor\", \"Actor_FIPS\", \"Partner\", \"Partner_FIPS\"]]\n",
    "assert df.shape[0] == 188*187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_serv = df_mx.pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"Exports\").reset_index()\n",
    "dt = pd.merge(left=df, right=export_serv, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "# takes about 1-2mins for all tables\n",
    "Ear=[]\n",
    "Rec=[]\n",
    "for i in range(dt.shape[0]):\n",
    "    line=dt.iloc[i,4:]\n",
    "    line.dropna(inplace=True)\n",
    "    if not line.empty:\n",
    "        Ear.append(line.values[0])\n",
    "        Rec.append(line.values[-1])\n",
    "    else:\n",
    "        Ear.append(np.NaN)\n",
    "        Rec.append(np.NaN)\n",
    "dt[\"Earliest\"]=Ear\n",
    "dt[\"MostRecent\"]=Rec\n",
    "dt.to_csv(f\"output/IFs Format/SeriesExportsServ.csv\", index=False, encoding=\"latin-1\")\n",
    "###\n",
    "import_serv = df_mx.pivot(index=[\"Actor\",\"Partner\"], columns = \"Year\", values=\"Imports\").reset_index()\n",
    "dt = pd.merge(left=df, right=import_serv, on=[\"Actor\",\"Partner\"], how=\"left\")\n",
    "# takes about 1-2mins for all tables\n",
    "Ear=[]\n",
    "Rec=[]\n",
    "for i in range(dt.shape[0]):\n",
    "    line=dt.iloc[i,4:]\n",
    "    line.dropna(inplace=True)\n",
    "    if not line.empty:\n",
    "        Ear.append(line.values[0])\n",
    "        Rec.append(line.values[-1])\n",
    "    else:\n",
    "        Ear.append(np.NaN)\n",
    "        Rec.append(np.NaN)\n",
    "dt[\"Earliest\"]=Ear\n",
    "dt[\"MostRecent\"]=Rec\n",
    "dt.to_csv(f\"output/IFs Format/SeriesImportsServ.csv\", index=False, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### total 2000-2022\n",
    "# exports \n",
    "x_goods = pd.read_csv(\"output/IFs Format/SeriesExportsGoods.csv\", encoding=\"latin-1\")\n",
    "x_serv = pd.read_csv(\"output/IFs Format/SeriesExportsServ.csv\", encoding=\"latin-1\")\n",
    "y_same = [y for y in x_serv.columns if y in x_goods.columns]\n",
    "x_serv_value = x_serv[y_same].drop(columns=['Actor','Actor_FIPS','Partner','Partner_FIPS', \"Earliest\", \"MostRecent\"])\n",
    "x_goods_value = x_goods[y_same].drop(columns=['Actor','Actor_FIPS','Partner','Partner_FIPS', \"Earliest\", \"MostRecent\"])\n",
    "x_tot_value = x_goods_value.add(x_serv_value,fill_value=0)\n",
    "dt = pd.concat([x_goods[x_goods.columns[:4]],x_tot_value], axis=1)\n",
    "Ear=[]\n",
    "Rec=[]\n",
    "for i in range(dt.shape[0]):\n",
    "    line=dt.iloc[i,4:]\n",
    "    line.dropna(inplace=True)\n",
    "    if not line.empty:\n",
    "        Ear.append(line.values[0])\n",
    "        Rec.append(line.values[-1])\n",
    "    else:\n",
    "        Ear.append(np.NaN)\n",
    "        Rec.append(np.NaN)\n",
    "dt[\"Earliest\"]=Ear\n",
    "dt[\"MostRecent\"]=Rec\n",
    "dt.to_csv(f\"output/IFs Format/SeriesExportsTotal.csv\", index=False, encoding=\"latin-1\")\n",
    "# imports\n",
    "m_goods = pd.read_csv(\"output/IFs Format/SeriesImportsGoods.csv\", encoding=\"latin-1\")\n",
    "m_serv = pd.read_csv(\"output/IFs Format/SeriesImportsServ.csv\", encoding=\"latin-1\")\n",
    "y_same = [y for y in m_serv.columns if y in m_goods.columns]\n",
    "m_serv_value = m_serv[y_same].drop(columns=['Actor','Actor_FIPS','Partner','Partner_FIPS', \"Earliest\", \"MostRecent\"])\n",
    "m_goods_value = m_goods[y_same].drop(columns=['Actor','Actor_FIPS','Partner','Partner_FIPS', \"Earliest\", \"MostRecent\"])\n",
    "m_tot_value = m_goods_value.add(m_serv_value,fill_value=0)\n",
    "dt = pd.concat([m_goods[m_goods.columns[:4]],m_tot_value], axis=1)\n",
    "Ear=[]\n",
    "Rec=[]\n",
    "for i in range(dt.shape[0]):\n",
    "    line=dt.iloc[i,4:]\n",
    "    line.dropna(inplace=True)\n",
    "    if not line.empty:\n",
    "        Ear.append(line.values[0])\n",
    "        Rec.append(line.values[-1])\n",
    "    else:\n",
    "        Ear.append(np.NaN)\n",
    "        Rec.append(np.NaN)\n",
    "dt[\"Earliest\"]=Ear\n",
    "dt[\"MostRecent\"]=Rec\n",
    "dt.to_csv(f\"output/IFs Format/SeriesImportsTotal.csv\", index=False, encoding=\"latin-1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
